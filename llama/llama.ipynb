{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ8j8XIq2D2V",
        "outputId": "dcc34514-9e4c-4460-df8e-d7b528c0dc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown sentencepiece transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEpv2j3rTp2n",
        "outputId": "78efa2c8-8a49-4f47-a260-a058662ea503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LV2Ye7jIs0IXzXqy5xBYlOTdVbEOot4L\n",
            "To: /content/model.zip\n",
            "100% 6.17G/6.17G [00:59<00:00, 104MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1LV2Ye7jIs0IXzXqy5xBYlOTdVbEOot4L\n",
        "# !gdown https://drive.google.com/uc?id=1C_vK6X78Pfp80C5AtTWR2HFCxhg378kX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6yYbHUFWa4V"
      },
      "outputs": [],
      "source": [
        "!mkdir model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f48lDjGdWcdM",
        "outputId": "0ec6b615-5bd1-4593-a109-4c884274a958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.zip\n",
            "   creating: model/model/\n",
            "  inflating: model/model/model.layers.14.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.13.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.3.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.8.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.2.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.17.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.3.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.4.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.21.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.2.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.22.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.8.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.22.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.21.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.19.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.6.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.15.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.16.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.6.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.15.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.13.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.6.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.21.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.8.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.15.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.6.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.8.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.7.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.20.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.3.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.6.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.16.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/lm_head.weight.npy  \n",
            "  inflating: model/model/model.layers.4.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.15.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.20.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.1.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.8.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.8.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.2.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.15.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.15.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.21.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.2.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.embed_tokens.weight.npy  \n",
            "  inflating: model/model/model.layers.20.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.5.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.2.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.3.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.6.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.23.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.6.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.21.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.6.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.3.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.5.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.21.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.20.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.15.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.8.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.2.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.11.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.2.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.15.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.1.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.25.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.14.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.21.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.16.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.21.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.14.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.19.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.2.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.17.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.23.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.4.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.6.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.5.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.3.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.13.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.21.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.22.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.1.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.23.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.4.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.7.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.25.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.3.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.8.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.18.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.11.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.19.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.2.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.24.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.5.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.norm.weight.npy  \n",
            "  inflating: model/model/model.layers.9.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.mlp.gate_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.3.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.23.self_attn.k_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.15.mlp.down_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.19.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.22.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.9.input_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.3.self_attn.v_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.12.self_attn.q_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.0.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.self_attn.o_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.7.post_attention_layernorm.weight.npy  \n",
            "  inflating: model/model/model.layers.8.mlp.up_proj.weight.npy  \n",
            "  inflating: model/model/model.layers.10.self_attn.k_proj.weight.npy  \n"
          ]
        }
      ],
      "source": [
        "!unzip model.zip -d model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwZyh532mpaA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import math\n",
        "import inspect\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71s4h1GouaoW"
      },
      "outputs": [],
      "source": [
        "# open llama 3b\n",
        "params = {\"dim\":3200, \"n_layers\": 26, \"n_heads\": 32, \"vocab_size\":32000, \"eps\":1e-6, \"ctx_len\": 2048, \"dropout\": 0.0, \"hidden_dim\":8640, \"attn_gpu\": True, \"mlp_gpu\": True, \"embed_gpu\":True, \"lm_head_gpu\":True}\n",
        "# llama 2 7b\n",
        "# params = {\"dim\":4096, \"n_layers\": 32, \"n_heads\": 32, \"vocab_size\":32000, \"eps\":1e-6, \"ctx_len\": 2048, \"dropout\": 0.0, \"hidden_dim\":8640, \"attn_gpu\": False, \"mlp_gpu\": True, \"embed_gpu\":True, \"lm_head_gpu\":True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6Zx2XespIxE"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "  def __call__(self, *args, **kwargs):\n",
        "    return self.forward(*args, **kwargs)\n",
        "\n",
        "  def parameters(self):\n",
        "    words = [\"c\",\"s\", \"mask\"]\n",
        "    total = 0\n",
        "    for n, m in inspect.getmembers(self):\n",
        "      if isinstance(m, np.ndarray) or isinstance(m, cp.ndarray):\n",
        "        if n not in words:\n",
        "          total+=m.size\n",
        "      if isinstance(m, Module):\n",
        "        total += m.parameters()\n",
        "    return total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsGsaEC6BgAW"
      },
      "outputs": [],
      "source": [
        "class ModuleList(Module):\n",
        "  def __init__(self, lst):\n",
        "    self.lst = lst\n",
        "    self.id = 0\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.id == len(self.lst):\n",
        "      self.id = 0\n",
        "      raise StopIteration\n",
        "    self.id += 1\n",
        "    return self.lst[self.id - 1]\n",
        "\n",
        "  def parameters(self):\n",
        "    total = 0\n",
        "    for l in self.lst:\n",
        "      total += l.parameters()\n",
        "    return total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZB-KczHpW1U"
      },
      "outputs": [],
      "source": [
        "def k_init(*shape, a=1, gpu = False):\n",
        "    std = math.sqrt(a / max(shape[0], shape[1]))\n",
        "    a = std\n",
        "    low = -a\n",
        "    high = a\n",
        "    if gpu:\n",
        "      return cp.random.uniform(low, high, shape).astype(cp.float16)\n",
        "    return np.random.uniform(low, high, shape).astype(np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjLCKs93_34v"
      },
      "outputs": [],
      "source": [
        "class linear(Module):\n",
        "  def __init__(self, inpt, out, filename=\"\", gpu = False):\n",
        "    if filename == \"\":\n",
        "      self.w = k_init(inpt, out, gpu = gpu)\n",
        "    else:\n",
        "      if gpu:\n",
        "        self.w = cp.load(filename).T\n",
        "      else:\n",
        "        self.w = np.load(filename).T\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x @ self.w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1arw7ycADMW"
      },
      "outputs": [],
      "source": [
        "class embedding(Module):\n",
        "  def __init__(self,vocab,n_embd, filename=\"\", gpu = False):\n",
        "    if filename == \"\":\n",
        "      self.w = k_init(vocab, n_embd, gpu = False)\n",
        "    else:\n",
        "      if gpu:\n",
        "        self.w = cp.load(filename)\n",
        "      else:\n",
        "        self.w = np.load(filename)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.w[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr0FxvgyAPDm"
      },
      "outputs": [],
      "source": [
        "def softmax(x, dim=-1, gpu = False):\n",
        "  if gpu:\n",
        "    ex = cp.exp(x)\n",
        "  else:\n",
        "    ex = np.exp(x)\n",
        "  return ex / ex.sum(axis = dim, keepdims= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNdxQQEBpeiD"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1+cp.exp(-x))\n",
        "\n",
        "def silu(x):\n",
        "  return x * sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYD_6wjPpuPt"
      },
      "outputs": [],
      "source": [
        "class dropout(Module):\n",
        "  def __init__(self, p):\n",
        "    self.p = p\n",
        "\n",
        "  def forward(self,x):\n",
        "    p = self.p\n",
        "    if p == 0:\n",
        "      return x\n",
        "    mask = np.random.binomial(1, 1 - p, x.shape)\n",
        "    out = x * mask\n",
        "    out /= (1 - p)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ub7HHHdpyQZ"
      },
      "outputs": [],
      "source": [
        "class rmsnorm(Module):\n",
        "  def __init__(self, dim,filename=\"\",eps=1e-6, gpu = False):\n",
        "    self.eps = eps\n",
        "    self.gpu = gpu\n",
        "    if gpu:\n",
        "      if filename == \"\":\n",
        "        self.weight = cp.ones(dim)\n",
        "      else:\n",
        "        self.weight = cp.load(filename)\n",
        "    else:\n",
        "      if filename == \"\":\n",
        "        self.weight = np.ones(dim)\n",
        "      else:\n",
        "        self.weight = np.load(filename)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.gpu:\n",
        "      x = x.astype(cp.float64)\n",
        "      x = x / cp.sqrt(cp.power(x,2).mean(axis=-1, keepdims=True) + self.eps)\n",
        "      return (x * self.weight).astype(cp.float16)\n",
        "    x = x.astype(np.float64)\n",
        "    x = x / np.sqrt(np.power(x,2).mean(axis=-1, keepdims=True) + self.eps)\n",
        "    return (x * self.weight).astype(np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_0odiur89Di"
      },
      "outputs": [],
      "source": [
        "class RoPE(Module):\n",
        "  def __init__(self, params, gpu=False):\n",
        "    self.dim = params[\"dim\"] // params[\"n_heads\"]\n",
        "    self.ctx_len = params[\"ctx_len\"]\n",
        "    self.gpu = gpu\n",
        "\n",
        "  @staticmethod\n",
        "  def build_cs_cache(dim, ctx_len, gpu =False):\n",
        "    theta = np.power(10000, -2*(np.arange(dim//2))/dim)\n",
        "    seq = np.arange(ctx_len)\n",
        "    seq_theta = np.outer(seq, theta)\n",
        "    ot = np.cos(seq_theta).astype(np.float16), np.sin(seq_theta).astype(np.float16)\n",
        "    if gpu:\n",
        "      return cp.asarray(ot)\n",
        "    return ot\n",
        "\n",
        "  def forward(self, x,c ,s):\n",
        "    \"\"\"\n",
        "    Expects x to be of shape (B, T, n_heads, dim)\n",
        "    \"\"\"\n",
        "    T = x.shape[1]\n",
        "    xs = x.reshape(*x.shape[:-1], self.dim//2, 2)\n",
        "\n",
        "    c, s = c[:T].reshape(1,T,1, self.dim//2), s[:T].reshape(1,T,1, self.dim//2)\n",
        "\n",
        "    if self.gpu:\n",
        "\n",
        "      return cp.stack([\n",
        "          xs[...,0] * c - xs[...,1] * s,\n",
        "          xs[...,1] * c + xs[...,0] * s\n",
        "      ],axis=-1).reshape(*x.shape)\n",
        "    return np.stack([\n",
        "        xs[...,0] * c - xs[...,1] * s,\n",
        "        xs[...,1] * c + xs[...,0] * s\n",
        "    ],axis=-1).reshape(*x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G54f8Mh8vkHW"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(Module):\n",
        "  def __init__(self,params=params, filename = {}, gpu = False):\n",
        "    self.dim = params[\"dim\"]\n",
        "    self.n_heads = params[\"n_heads\"]\n",
        "    self.eps = params[\"eps\"]\n",
        "    self.ctx_len = params[\"ctx_len\"]\n",
        "    if len(filename.keys()) == 0:\n",
        "      self.query = linear(self.dim, self.dim, gpu = gpu)\n",
        "      self.key = linear(self.dim, self.dim, gpu = gpu)\n",
        "      self.value = linear(self.dim, self.dim, gpu = gpu)\n",
        "      self.o = linear(self.dim, self.dim, gpu= gpu)\n",
        "    else:\n",
        "      self.query = linear(self.dim, self.dim, filename =filename[\"q_proj\"], gpu=gpu)\n",
        "      self.key = linear(self.dim, self.dim, filename = filename[\"k_proj\"], gpu=gpu)\n",
        "      self.value = linear(self.dim, self.dim, filename = filename[\"v_proj\"], gpu=gpu)\n",
        "      self.o = linear(self.dim, self.dim, filename = filename[\"o_proj\"], gpu = gpu)\n",
        "    self.gpu = gpu\n",
        "    self.rope = RoPE(params, gpu = gpu)\n",
        "\n",
        "  def forward(self, x, mask, c, s):\n",
        "    if self.gpu:\n",
        "      x = cp.asarray(x)\n",
        "    else:\n",
        "      x = cp.asnumpy(x)\n",
        "\n",
        "    B,T,C = x.shape\n",
        "    qkv = self.query(x), self.key(x), self.value(x)\n",
        "    q,k,v = [i.reshape(B, T, self.n_heads, C//self.n_heads) for i in qkv]\n",
        "    q = self.rope(q,c,s)\n",
        "    k = self.rope(k,c,s)\n",
        "    q = q.transpose((0,2,1,3))\n",
        "    k = k.transpose((0,2,1,3))\n",
        "    v = v.transpose((0,2,1,3))\n",
        "    scores = (q @ k.transpose((0,1,3,2))) / math.sqrt(C//self.n_heads)\n",
        "    scores = scores + mask[:,:,:T,:T]\n",
        "    scores = softmax(scores.astype(np.float64), gpu=self.gpu).astype(np.float16)\n",
        "    scores = (scores @ v).transpose((0,2,1,3)).reshape((B,T,C))\n",
        "    return self.o(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGYyabzC5Y7t"
      },
      "outputs": [],
      "source": [
        "class MLP(Module):\n",
        "  def __init__(self,params, filename = {}, gpu = True):\n",
        "    self.gpu = gpu\n",
        "    self.dim = params[\"dim\"]\n",
        "    self.hidden = params[\"hidden_dim\"]\n",
        "    if len(filename.keys()) == 0:\n",
        "      self.w1 = linear(self.dim, self.hidden, gpu = gpu) # gate_proj\n",
        "      self.w2 = linear(self.hidden, self.dim, gpu = gpu) # down_proj\n",
        "      self.w3 = linear(self.dim, self.hidden, gpu = gpu) # up_proj\n",
        "    else:\n",
        "      self.w1 = linear(self.dim, self.hidden, gpu = gpu,filename = filename[\"gate_proj\"]) # gate_proj\n",
        "      self.w2 = linear(self.hidden, self.dim, gpu = gpu, filename=filename[\"down_proj\"]) # down_proj\n",
        "      self.w3 = linear(self.dim, self.hidden, gpu = gpu, filename = filename[\"up_proj\"]) # up_proj\n",
        "  def forward(self, x):\n",
        "    if self.gpu:\n",
        "      x = cp.asarray(x)\n",
        "    else:\n",
        "      x = cp.asnumpy(x)\n",
        "    return self.w2(silu(self.w1(x)) * self.w3(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ozleg3h3br"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Module):\n",
        "  def __init__(self, params, filename = {}):\n",
        "    if len(filename.keys()) == 0:\n",
        "      self.post_attn_norm = rmsnorm(params['dim'], gpu = True)\n",
        "      self.post_inpt = rmsnorm(params[\"dim\"])\n",
        "      self.attn = MultiheadAttention(params)\n",
        "      self.mlp = MLP(params)\n",
        "    else:\n",
        "      self.post_attn_norm = rmsnorm(params['dim'], gpu = params[\"mlp_gpu\"], filename = filename[\"post_attention_layernorm\"])\n",
        "      self.post_inpt = rmsnorm(params[\"dim\"],gpu=params[\"attn_gpu\"],filename = filename[\"input_layernorm\"])\n",
        "      self.attn = MultiheadAttention(params, filename = filename[\"attn\"], gpu=params[\"attn_gpu\"])\n",
        "      self.mlp = MLP(params, filename = filename[\"mlp\"], gpu=params[\"mlp_gpu\"])\n",
        "    self.params = params\n",
        "\n",
        "  def forward(self, x, mask, c, s):\n",
        "    if self.params[\"attn_gpu\"]:\n",
        "      x = cp.asarray(x)\n",
        "    else:\n",
        "      x = cp.asnumpy(x)\n",
        "\n",
        "    x = x + self.attn(self.post_inpt(x), mask, c,s)\n",
        "\n",
        "    if self.params[\"mlp_gpu\"]:\n",
        "      x = cp.asarray(x)\n",
        "    else:\n",
        "      x = cp.asnumpy(x)\n",
        "\n",
        "    x = x + self.mlp(self.post_attn_norm(x))\n",
        "    return cp.asnumpy(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlCXayh-i4Kt"
      },
      "outputs": [],
      "source": [
        "class llama(Module):\n",
        "  def __init__(self, params, filename= {}):\n",
        "    if len(filename.keys()) == 0:\n",
        "      self.w_embed = embedding(params[\"vocab_size\"], params[\"dim\"], gpu = params[\"embed_gpu\"])\n",
        "      self.layers = ModuleList([TransformerBlock(params) for _ in range(params[\"n_layers\"])])\n",
        "      self.norm = rmsnorm(params[\"dim\"])\n",
        "      self.lm_head = linear(params[\"dim\"], params[\"vocab_size\"], bias = False, gpu=params[\"lm_head_gpu\"])\n",
        "    else:\n",
        "      self.w_embed = embedding(params[\"vocab_size\"], params[\"dim\"], filename=filename[\"w_embed\"], gpu = params[\"embed_gpu\"])\n",
        "      self.layers = ModuleList([TransformerBlock(params, filename = f) for f in filename[\"blocks\"]])\n",
        "      self.norm = rmsnorm(params[\"dim\"], filename = filename[\"final_norm\"], gpu = params[\"lm_head_gpu\"])\n",
        "      self.lm_head = linear(params[\"dim\"], params[\"vocab_size\"], filename = filename[\"lm_head\"], gpu=params[\"lm_head_gpu\"])\n",
        "    self.c,self.s = RoPE.build_cs_cache(params[\"dim\"]//params[\"n_heads\"], params[\"ctx_len\"], gpu=params[\"attn_gpu\"])\n",
        "    self.mask = (-1/np.tril(np.ones((params[\"ctx_len\"],params[\"ctx_len\"]))) + 1)[np.newaxis,np.newaxis].astype(np.float16)\n",
        "\n",
        "    if params[\"attn_gpu\"]:\n",
        "      self.mask = cp.asarray(self.mask)\n",
        "    self.params = params\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.w_embed(x)\n",
        "    for layer in self.layers:\n",
        "      y = layer(y,self.mask, self.c, self.s)\n",
        "\n",
        "    if self.params[\"lm_head_gpu\"]:\n",
        "      y = cp.asarray(y)\n",
        "    else:\n",
        "      y = cp.asnumpy(y)\n",
        "\n",
        "    y = self.norm(y)\n",
        "    return cp.asnumpy(self.lm_head(y))\n",
        "\n",
        "  def generate(self, x, max_new = 10):\n",
        "    for _ in tqdm(range(max_new)):\n",
        "      if x.shape[1] < params[\"ctx_len\"]:\n",
        "        x_c = x\n",
        "      else:\n",
        "        x_c = x[:,-params[\"ctx_len\"]:]\n",
        "      p = self.forward(x)\n",
        "      new_tok = p[:,-1,:]\n",
        "      probs = softmax(new_tok.astype(np.float64))\n",
        "      nxt = np.argmax(np.random.multinomial(1,probs[0]), keepdims=True)[np.newaxis]\n",
        "      x = np.concatenate((x, nxt), axis=-1)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8SOE6s0DIY2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ot = {}\n",
        "lst = os.listdir(\"model/model\")\n",
        "ot[\"lm_head\"] = \"model/model/lm_head.weight.npy\"\n",
        "ot[\"w_embed\"] = \"model/model/model.embed_tokens.weight.npy\"\n",
        "ot[\"final_norm\"]  = \"model/model/model.norm.weight.npy\"\n",
        "blocks = []\n",
        "labels =  [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"down_proj\", \"up_proj\", \"input_layernorm\", \"post_attention_layernorm\"]\n",
        "\n",
        "for ind in range(params[\"n_layers\"]):\n",
        "  keys = [i for i in lst if f\"layers.{ind}.\" in i]\n",
        "  overall = {\"attn\":{}, \"mlp\":{}}\n",
        "  for j in labels[:4]:\n",
        "    overall[\"attn\"][j] = \"model/model/\"+[i for i in keys if j in i][0]\n",
        "  for j in labels[4:7]:\n",
        "    overall[\"mlp\"][j] = \"model/model/\"+[i for i in keys if j in i][0]\n",
        "  for j in labels[7:]:\n",
        "    overall[j] = \"model/model/\"+[i for i in keys if j in i][0]\n",
        "  blocks.append(overall)\n",
        "ot[\"blocks\"] = blocks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Wc9L_rgpGi",
        "outputId": "8badc680-5d36-4bbc-919e-0819e16538e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-c28508d51157>:14: RuntimeWarning: divide by zero encountered in divide\n",
            "  self.mask = (-1/np.tril(np.ones((params[\"ctx_len\"],params[\"ctx_len\"]))) + 1)[np.newaxis,np.newaxis].astype(np.float16)\n"
          ]
        }
      ],
      "source": [
        "model = llama(params, ot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aayzdJHKdosO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "8bb705a6e7164dbf8707144b6a7c139d",
            "ef6045ddaa7b4f45b711b9e9424014c7",
            "b738a039321d41f5a89881f98f8154ca",
            "e77775156a964bdfa240ddc215fd3a44",
            "24cdbca122b94825becaf48ff3c67f3e",
            "87be4f9b83aa4da8ada47b2e89953c1d",
            "dae3da8d49da4d74bb83c41cacca833a",
            "0f2916e1af8f47b8ba9017eb126775f2",
            "827b80f8723b4bf99bd30bd1f9ab7ee5",
            "bba1ba8e0a7c43c28e3136959a3aaeeb",
            "23a0219669b749c89e732cce64e289ff",
            "2894c1892ce44fa2ada6c67fa181d091",
            "d15c3da434224722b2b6c460d0ec74f2",
            "764100a34e4f41459132d347724ad9da",
            "54be0512bba14aee818b0f8e7a090ee8",
            "1ff1f4d2d87c48da81606e66fc33b2eb",
            "e673977f4c9943efbbf7f96df387f37d",
            "bab6a0e7766843abbae65df309116806",
            "9c41324a4df949108f85fa7ac9f78656",
            "65a2757fa59f419db7d3f6c36077a835",
            "aec1a715f2384dc3b2d11d4020b929c8",
            "aa4694a0e5c5492f8caaf5b4a2ec2451",
            "5434388bf94a445d88d59f9d4e85590a",
            "c042752579e9450cb51e0ab4b2425abc",
            "4535c58ef2584e5c857ca2062a67664d",
            "db2d5525e2d946f980968a776656e095",
            "9b5c6661ddcb4ccc8b9c8581eac4cefc",
            "a9770b327cf84245962b081abe2f194b",
            "0baac5be89b94f0680a3858f09dd2b62",
            "7c885945f0fe4fdfa034c3e8c0995837",
            "9ff91b6c7072433f8fd15c1b30fc0e4e",
            "4891206bc93145c796980e7d29df5ffc",
            "a630abf2b2c84f01b3ec8abb80df065b"
          ]
        },
        "outputId": "c52fa045-d8a3-471f-d495-b28cb1a0c91c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/593 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bb705a6e7164dbf8707144b6a7c139d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/512k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2894c1892ce44fa2ada6c67fa181d091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/330 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5434388bf94a445d88d59f9d4e85590a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate(model, x, max_new = 10):\n",
        "  for _ in tqdm(range(max_new)):\n",
        "    if x.shape[1] < params[\"ctx_len\"]:\n",
        "      x_c = x\n",
        "    else:\n",
        "      x_c = x[:,-params[\"ctx_len\"]:]\n",
        "    p = model.forward(x)\n",
        "    print(p)\n",
        "    new_tok = p[:,-1,:]\n",
        "    # print(new_tok)\n",
        "    probs = softmax(new_tok.astype(np.float64))\n",
        "    # print(np.argmax(probs, keepdims=True))\n",
        "    nxt = np.argmax(probs, keepdims=True)\n",
        "    print(nxt)\n",
        "    # nxt = np.argmax(np.random.multinomial(1,probs[0]), keepdims=True)[np.newaxis]\n",
        "    x = np.concatenate((x, nxt), axis=-1)\n",
        "\n",
        "  return x\n",
        "\n",
        "ot = generate(model, tokenizer.encode(\"Hola\", return_tensors=\"np\"), max_new=1)\n",
        "tokenizer.decode(ot[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "McE0k5bLK0UR",
        "outputId": "8d6f1d81-98c9-4cc9-df0f-78fc2dbaa467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:13<00:00, 13.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-17.11  -12.27  -11.73  ... -15.484 -17.47  -16.3  ]\n",
            "  [-24.17  -23.7   -15.13  ... -24.06  -24.56  -22.77 ]\n",
            "  [-62.9   -63.62  -54.34  ... -65.4   -64.44  -63.22 ]]]\n",
            "[[29522]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Hola,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bb705a6e7164dbf8707144b6a7c139d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef6045ddaa7b4f45b711b9e9424014c7",
              "IPY_MODEL_b738a039321d41f5a89881f98f8154ca",
              "IPY_MODEL_e77775156a964bdfa240ddc215fd3a44"
            ],
            "layout": "IPY_MODEL_24cdbca122b94825becaf48ff3c67f3e"
          }
        },
        "ef6045ddaa7b4f45b711b9e9424014c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87be4f9b83aa4da8ada47b2e89953c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_dae3da8d49da4d74bb83c41cacca833a",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b738a039321d41f5a89881f98f8154ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2916e1af8f47b8ba9017eb126775f2",
            "max": 593,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_827b80f8723b4bf99bd30bd1f9ab7ee5",
            "value": 593
          }
        },
        "e77775156a964bdfa240ddc215fd3a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba1ba8e0a7c43c28e3136959a3aaeeb",
            "placeholder": "​",
            "style": "IPY_MODEL_23a0219669b749c89e732cce64e289ff",
            "value": " 593/593 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "24cdbca122b94825becaf48ff3c67f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87be4f9b83aa4da8ada47b2e89953c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae3da8d49da4d74bb83c41cacca833a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f2916e1af8f47b8ba9017eb126775f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827b80f8723b4bf99bd30bd1f9ab7ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bba1ba8e0a7c43c28e3136959a3aaeeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a0219669b749c89e732cce64e289ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2894c1892ce44fa2ada6c67fa181d091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d15c3da434224722b2b6c460d0ec74f2",
              "IPY_MODEL_764100a34e4f41459132d347724ad9da",
              "IPY_MODEL_54be0512bba14aee818b0f8e7a090ee8"
            ],
            "layout": "IPY_MODEL_1ff1f4d2d87c48da81606e66fc33b2eb"
          }
        },
        "d15c3da434224722b2b6c460d0ec74f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e673977f4c9943efbbf7f96df387f37d",
            "placeholder": "​",
            "style": "IPY_MODEL_bab6a0e7766843abbae65df309116806",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "764100a34e4f41459132d347724ad9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c41324a4df949108f85fa7ac9f78656",
            "max": 511574,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65a2757fa59f419db7d3f6c36077a835",
            "value": 511574
          }
        },
        "54be0512bba14aee818b0f8e7a090ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec1a715f2384dc3b2d11d4020b929c8",
            "placeholder": "​",
            "style": "IPY_MODEL_aa4694a0e5c5492f8caaf5b4a2ec2451",
            "value": " 512k/512k [00:00&lt;00:00, 18.8MB/s]"
          }
        },
        "1ff1f4d2d87c48da81606e66fc33b2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e673977f4c9943efbbf7f96df387f37d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab6a0e7766843abbae65df309116806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c41324a4df949108f85fa7ac9f78656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a2757fa59f419db7d3f6c36077a835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aec1a715f2384dc3b2d11d4020b929c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4694a0e5c5492f8caaf5b4a2ec2451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5434388bf94a445d88d59f9d4e85590a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c042752579e9450cb51e0ab4b2425abc",
              "IPY_MODEL_4535c58ef2584e5c857ca2062a67664d",
              "IPY_MODEL_db2d5525e2d946f980968a776656e095"
            ],
            "layout": "IPY_MODEL_9b5c6661ddcb4ccc8b9c8581eac4cefc"
          }
        },
        "c042752579e9450cb51e0ab4b2425abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9770b327cf84245962b081abe2f194b",
            "placeholder": "​",
            "style": "IPY_MODEL_0baac5be89b94f0680a3858f09dd2b62",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "4535c58ef2584e5c857ca2062a67664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c885945f0fe4fdfa034c3e8c0995837",
            "max": 330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ff91b6c7072433f8fd15c1b30fc0e4e",
            "value": 330
          }
        },
        "db2d5525e2d946f980968a776656e095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4891206bc93145c796980e7d29df5ffc",
            "placeholder": "​",
            "style": "IPY_MODEL_a630abf2b2c84f01b3ec8abb80df065b",
            "value": " 330/330 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "9b5c6661ddcb4ccc8b9c8581eac4cefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9770b327cf84245962b081abe2f194b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0baac5be89b94f0680a3858f09dd2b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c885945f0fe4fdfa034c3e8c0995837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff91b6c7072433f8fd15c1b30fc0e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4891206bc93145c796980e7d29df5ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a630abf2b2c84f01b3ec8abb80df065b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}